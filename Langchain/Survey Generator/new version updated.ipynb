{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f8e6b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, csv, os, sys\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "from typing import List\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c826bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(output_file, data):\n",
    "    with open(output_file, 'a', newline='', encoding='utf-8') as outfile:  \n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9431965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_txt(txt_path, data):\n",
    "    with open(txt_path, 'a') as txf:\n",
    "        txf.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c1dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables\n",
    "\n",
    "model_name = 'gpt-4-1106-preview'  #gpt model name\n",
    "title = 'Survey for brand awareness'  #title\n",
    "audience = 'Normal People living in US' #audience\n",
    "output_file = 'hawkRun1.csv'\n",
    "txt_file = 'output.txt'\n",
    "\n",
    "#you can change questions and traits/count as you want, this part has become dynamic in this notebook.\n",
    "questions = [\n",
    "\"Which city do you live in?\",\n",
    "\"Which state do you live in?\"\n",
    "]\n",
    "\n",
    "traits_and_counts = [\n",
    "    ('Woman 60+ that owns 1 dog', 100)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f82ba8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block of code is not needed, it is there to know how function calling works.\n",
    "\n",
    "# To learn more about function calling, check this out https://www.datacamp.com/tutorial/open-ai-function-calling-tutorial\n",
    "#Answer is the class which contains response given by each user, it also contain traits to know which person answered the questions.\n",
    "#llm is inteligent enough to give unique response each time based on the given system and user prompt, we should not worry about it.\n",
    "class Answer(BaseModel):\n",
    "    \"\"\"Human-like set of answers told by each person while being surveyed. \n",
    "    Each person should have their own unique set of answers that should be different from other person's set of answers.\"\"\"\n",
    "\n",
    "    answer1: str = Field(description=\"This is the human like answer to Question1.\")\n",
    "    answer2: str = Field(description=\"This is the human like answer to Question2.\")\n",
    "    answer3: str = Field(description=\"This is the human like answer to Question3.\")\n",
    "    answer4: str = Field(description=\"This is the human like answer to Question4.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "#list of answers, the formatted list that the llm model will generate which contains dictionaries of Answer class\n",
    "#llm model will make sure that each dictionary in the list is unique from each other as it will treat the list like list of human responses.\n",
    "class Answers(BaseModel):\n",
    "    \"\"\"Human-like survey answers to tell user.\"\"\"\n",
    "\n",
    "    answer: List[Answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fc7f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "848abc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is standard pattern of list of functions used for function calling.\n",
    "# To know the pattern, you can print out openai_functions variable in previous New.ipynb file\n",
    "# This function is responsible to give the output list of answers of each human that we want, based on the parameters provided.\n",
    "# To learn more about function calling, check this out https://www.datacamp.com/tutorial/open-ai-function-calling-tutorial\n",
    "def create_openai_functions(questions: List):\n",
    "    fn  = [{'name': 'Answers',\n",
    "            'description': 'Human-like survey answers to tell user.',\n",
    "            'parameters': {'type': 'object',\n",
    "            'properties': {'answer': {'type': 'array',\n",
    "                'items': {'description': \"Human-like set of answers told by each person while being surveyed. \\nEach person should have their own unique set of answers that should be different from other person's set of answers.\",\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                },\n",
    "                'required': []}}},\n",
    "            'required': ['answer']}}]\n",
    "    answers = fn[0]['parameters']['properties']['answer']['items']['properties']\n",
    "    required = fn[0]['parameters']['properties']['answer']['items']['required']\n",
    "    for ind, _ in enumerate(questions, 1):\n",
    "        answers[f'answer{ind}'] = {'description': f'This is the human like answer to Question{ind}.', 'type': 'string'}\n",
    "        required.append(f'answer{ind}')\n",
    "    return fn\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48af2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample openai function example\n",
    "openai_functions = create_openai_functions(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a51ced18",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JsonKeyOutputFunctionsParser(key_name=\"answer\")  # to parse the output, it will return list of answers based on function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbfabebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bind openai_functions to llm for function calling\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    model_name=model_name,\n",
    "    max_tokens=4095\n",
    ").bind(functions=openai_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "464a4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is default system message, you can change it based on your need.\n",
    "system_message = \"\"\"\n",
    "You are a survey answering bot that generates answers like a survey when questions are asked. The answer should be made as if you are a human. \n",
    "Give answers assuming you are a new human with different lifestyles while giving answers.\n",
    "Give answers with new thoughts, new ideas, new moods, you can also choose to answer very rudely, but the main idea is to be random, do not try to repeat same answers since humans have different answers with different answer style.\n",
    "While giving answers, you should be as creative as possible and you should deviate your answers as much as possible from previous answers.\n",
    "In every answer, change styles of answers, change average sentence lengths of answer, change fk_grade_level of sentences of answer. Make it different from previous answers. But also make sure it is the answer given by a human. So, don't make it seem like it is AI generated. Add both simple and fancy words.\n",
    "In 1 answer, give your answers assuming you are having a worse life, in another answer, give your answers assuming you are having best life. like this, keep on changing the lifestyle of human that you are.\n",
    "Avoid same repeated answers as much as possible.\n",
    "Do no repeat same pattern in each answers. Give short answers sometimes and sometimes long answers, be random.\n",
    "Since, human can give both positive and negative answers, you should follow the same principles.\n",
    "Your answers should be descriptive just like human answers.\n",
    "Each set of answers should be different from another set of answers. \n",
    "If you are asked about 'top few things' or 'few things', each answers should have random number of comma separated sentences. For example:\n",
    "sentence1, sentence2, and sentence3. (3 sentences)\n",
    "sentence1 (1 sentence)\n",
    "sentence1, sentence2, sentence3, sentence4, and sentence5. (5 sentences)\n",
    "sentence1, sentence2. (2 sentences)\n",
    "sentence1, sentence2, sentence3, and sentence4. (4 sentences)\n",
    "\n",
    "If the output asks for a monetary output give just the dollar amount and no text before or after it unless prompted to do so. So for example if the answer is $40 just give $40.\n",
    "If the output asks for a decimal output give just the value and no text before or after it unless prompted to do so. So for example if the answer is 40.5 just give 40.5.\n",
    "If you are asked a question like where do you live? Be sure to just answer the place that you live. No text before or after it is needed unless prompted to do so.\n",
    "If the answer is asking for a percentage output just give the value. So if the answer is 45% just give 45%. Do not give any text before or after that unless prompted to do so.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffcbdd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chat template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_message), (\"user\", \"{input}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29be918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chain using prompt, llm and parser\n",
    "#it uses the prompt with llm and generate the answer based on the parser\n",
    "\n",
    "# chain = prompt | llm | parser\n",
    "\n",
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe9869fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_parser(response):\n",
    "    try:\n",
    "        return eval(response.additional_kwargs['function_call']['arguments'])['answer']\n",
    "    except Exception as e:\n",
    "        # print(\"Error in Eval\\n\")\n",
    "        # print(e)\n",
    "        # print('----------------------------------------------------------------------')\n",
    "        try:\n",
    "            return json_repair.loads(response.additional_kwargs['function_call']['arguments'])['answer']\n",
    "        except Exception as e:\n",
    "            # print(\"Error in Json loads\")\n",
    "            # print(e)\n",
    "            # print('----------------------------------------------------------------------')\n",
    "            write_txt(txt_file, \"\\nFailed-eval-json-loads---------------------------------------\\n\\n\\n\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f953a30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Traits/counts dict: {'Woman 60+ that owns 1 dog': 100}\n",
      "Total remaining people to be surveyed: 100\n",
      "\n",
      "Remaining traits: {'Woman 60+ that owns 1 dog': 100}\n",
      "Total responses given by model: 126\n",
      "Total processed responses: 126\n",
      "[{'answer1': 'Tucson', 'answer2': 'Arizona'}, {'answer1': 'Sarasota', 'answer2': 'Florida'}, {'answer1': 'Albuquerque', 'answer2': 'New Mexico'}, {'answer1': 'Charleston', 'answer2': 'South Carolina'}, {'answer1': 'Santa Fe', 'answer2': 'New Mexico'}, {'answer1': 'San Diego', 'answer2': 'California'}, {'answer1': 'Portland', 'answer2': 'Maine'}, {'answer1': 'Fort Lauderdale', 'answer2': 'Florida'}, {'answer1': 'Tallahassee', 'answer2': 'Florida'}, {'answer1': 'Asheville', 'answer2': 'North Carolina'}, {'answer1': 'Austin', 'answer2': 'Texas'}, {'answer1': 'Savannah', 'answer2': 'Georgia'}, {'answer1': 'Scottsdale', 'answer2': 'Arizona'}, {'answer1': 'Colorado Springs', 'answer2': 'Colorado'}, {'answer1': 'Bellingham', 'answer2': 'Washington'}, {'answer1': 'Eugene', 'answer2': 'Oregon'}, {'answer1': 'Chattanooga', 'answer2': 'Tennessee'}, {'answer1': 'Naples', 'answer2': 'Florida'}, {'answer1': 'Ann Arbor', 'answer2': 'Michigan'}, {'answer1': 'Lancaster', 'answer2': 'Pennsylvania'}, {'answer1': 'Madison', 'answer2': 'Wisconsin'}, {'answer1': 'Rochester', 'answer2': 'Minnesota'}, {'answer1': 'Boise', 'answer2': 'Idaho'}, {'answer1': 'Palm Springs', 'answer2': 'California'}, {'answer1': 'Boulder', 'answer2': 'Colorado'}, {'answer1': 'Grand Rapids', 'answer2': 'Michigan'}, {'answer1': 'Santa Barbara', 'answer2': 'California'}, {'answer1': 'The Villages', 'answer2': 'Florida'}, {'answer1': 'Reno', 'answer2': 'Nevada'}, {'answer1': 'Honolulu', 'answer2': 'Hawaii'}, {'answer1': 'Spokane', 'answer2': 'Washington'}, {'answer1': 'Lexington', 'answer2': 'Kentucky'}, {'answer1': 'Greenville', 'answer2': 'South Carolina'}, {'answer1': 'Knoxville', 'answer2': 'Tennessee'}, {'answer1': 'Wilmington', 'answer2': 'North Carolina'}, {'answer1': 'Tallahassee', 'answer2': 'Florida'}, {'answer1': 'San Antonio', 'answer2': 'Texas'}, {'answer1': 'Olympia', 'answer2': 'Washington'}, {'answer1': 'Santa Cruz', 'answer2': 'California'}, {'answer1': 'Des Moines', 'answer2': 'Iowa'}, {'answer1': 'Fayetteville', 'answer2': 'Arkansas'}, {'answer1': 'Sarasota', 'answer2': 'Florida'}, {'answer1': 'Fort Myers', 'answer2': 'Florida'}, {'answer1': 'Durham', 'answer2': 'North Carolina'}, {'answer1': 'Charlottesville', 'answer2': 'Virginia'}, {'answer1': 'Baton Rouge', 'answer2': 'Louisiana'}, {'answer1': 'Columbia', 'answer2': 'South Carolina'}, {'answer1': 'Gainesville', 'answer2': 'Florida'}, {'answer1': 'Pensacola', 'answer2': 'Florida'}, {'answer1': 'Tucson', 'answer2': 'Arizona'}, {'answer1': 'El Paso', 'answer2': 'Texas'}, {'answer1': 'Santa Rosa', 'answer2': 'California'}, {'answer1': 'Burlington', 'answer2': 'Vermont'}, {'answer1': 'Melbourne', 'answer2': 'Florida'}, {'answer1': 'Lakeland', 'answer2': 'Florida'}, {'answer1': 'Topeka', 'answer2': 'Kansas'}, {'answer1': 'Springfield', 'answer2': 'Illinois'}, {'answer1': 'Salem', 'answer2': 'Oregon'}, {'answer1': 'San Luis Obispo', 'answer2': 'California'}, {'answer1': 'Ocala', 'answer2': 'Florida'}, {'answer1': 'Fort Collins', 'answer2': 'Colorado'}, {'answer1': 'Corpus Christi', 'answer2': 'Texas'}, {'answer1': 'Yuma', 'answer2': 'Arizona'}, {'answer1': 'Amarillo', 'answer2': 'Texas'}, {'answer1': 'Dayton', 'answer2': 'Ohio'}, {'answer1': 'Sioux Falls', 'answer2': 'South Dakota'}, {'answer1': 'Huntsville', 'answer2': 'Alabama'}, {'answer1': 'Rapid City', 'answer2': 'South Dakota'}, {'answer1': 'Lansing', 'answer2': 'Michigan'}, {'answer1': 'Prescott', 'answer2': 'Arizona'}, {'answer1': 'Winston-Salem', 'answer2': 'North Carolina'}, {'answer1': 'Erie', 'answer2': 'Pennsylvania'}, {'answer1': 'Fort Wayne', 'answer2': 'Indiana'}, {'answer1': 'Peoria', 'answer2': 'Illinois'}, {'answer1': 'Myrtle Beach', 'answer2': 'South Carolina'}, {'answer1': 'Mobile', 'answer2': 'Alabama'}, {'answer1': 'Trenton', 'answer2': 'New Jersey'}, {'answer1': 'Lubbock', 'answer2': 'Texas'}, {'answer1': 'Provo', 'answer2': 'Utah'}, {'answer1': 'Rochester', 'answer2': 'New York'}, {'answer1': 'Flagstaff', 'answer2': 'Arizona'}, {'answer1': 'Tallahassee', 'answer2': 'Florida'}, {'answer1': 'Springfield', 'answer2': 'Missouri'}, {'answer1': 'Laredo', 'answer2': 'Texas'}, {'answer1': 'Green Bay', 'answer2': 'Wisconsin'}, {'answer1': 'Shreveport', 'answer2': 'Louisiana'}, {'answer1': 'Kalamazoo', 'answer2': 'Michigan'}, {'answer1': 'Gulfport', 'answer2': 'Mississippi'}, {'answer1': 'Bend', 'answer2': 'Oregon'}, {'answer1': 'Albany', 'answer2': 'New York'}, {'answer1': 'Hagerstown', 'answer2': 'Maryland'}, {'answer1': 'Pueblo', 'answer2': 'Colorado'}, {'answer1': 'Wichita', 'answer2': 'Kansas'}, {'answer1': 'Evansville', 'answer2': 'Indiana'}, {'answer1': 'Duluth', 'answer2': 'Minnesota'}, {'answer1': 'Bakersfield', 'answer2': 'California'}, {'answer1': 'Augusta', 'answer2': 'Georgia'}, {'answer1': 'Fargo', 'answer2': 'North Dakota'}, {'answer1': 'Billings', 'answer2': 'Montana'}, {'answer1': 'Santa Maria', 'answer2': 'California'}, {'answer1': 'Chattanooga', 'answer2': 'Tennessee'}, {'answer1': 'Anchorage', 'answer2': 'Alaska'}, {'answer1': 'Manchester', 'answer2': 'New Hampshire'}, {'answer1': 'Eugene', 'answer2': 'Oregon'}, {'answer1': 'Lakewood', 'answer2': 'Colorado'}, {'answer1': 'Overland Park', 'answer2': 'Kansas'}, {'answer1': 'Norfolk', 'answer2': 'Virginia'}, {'answer1': 'Reading', 'answer2': 'Pennsylvania'}, {'answer1': 'Bismarck', 'answer2': 'North Dakota'}, {'answer1': 'Cheyenne', 'answer2': 'Wyoming'}, {'answer1': 'Syracuse', 'answer2': 'New York'}, {'answer1': 'Corvallis', 'answer2': 'Oregon'}, {'answer1': 'Lincoln', 'answer2': 'Nebraska'}, {'answer1': 'Monterey', 'answer2': 'California'}, {'answer1': 'Fresno', 'answer2': 'California'}, {'answer1': 'Baton Rouge', 'answer2': 'Louisiana'}, {'answer1': 'Allentown', 'answer2': 'Pennsylvania'}, {'answer1': 'Saginaw', 'answer2': 'Michigan'}, {'answer1': 'Davenport', 'answer2': 'Iowa'}, {'answer1': 'Fort Smith', 'answer2': 'Arkansas'}, {'answer1': 'Medford', 'answer2': 'Oregon'}, {'answer1': 'Lafayette', 'answer2': 'Louisiana'}, {'answer1': 'Modesto', 'answer2': 'California'}, {'answer1': 'Elkhart', 'answer2': 'Indiana'}, {'answer1': 'Greensboro', 'answer2': 'North Carolina'}, {'answer1': 'Salinas', 'answer2': 'California'}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_processed_row = 0  #total row processed\n",
    "total_remaining_surveyed = 0  #total people remaining to be surveyed\n",
    "person_number = 0  #person count\n",
    "traits_dict = {}\n",
    "\n",
    "\n",
    "for dta in traits_and_counts:\n",
    "    traits_dict[dta[0]] = int(dta[1])  #creating dict of traits and counts\n",
    "    total_remaining_surveyed += int(dta[1])  #total people remaining to be surveyed\n",
    "        \n",
    "if output_file not in os.listdir():  #if csv is not available\n",
    "    write_csv(output_file, ['Traits', 'Person Number']+questions)\n",
    "else: #if csv already exists\n",
    "    df = pd.read_csv(output_file)\n",
    "    old_traits_dict = df['Traits'].value_counts().to_dict() #get traits/counts of already surveyed people in csv\n",
    "    for k,v in old_traits_dict.items():\n",
    "        person_number += v #increasing the person number\n",
    "        if k not in traits_dict.keys(): \n",
    "            continue\n",
    "        traits_dict[k] = traits_dict[k]-v\n",
    "        total_remaining_surveyed = int(total_remaining_surveyed - v)  #subtracting from the people that are already in csv. suppose 7 needed, 3 are already in csv, it will only process 4\n",
    "        \n",
    "        \n",
    "print(\"Remaining Traits/counts dict:\", traits_dict)\n",
    "print(\"Total remaining people to be surveyed:\", total_remaining_surveyed)\n",
    "print()\n",
    "\n",
    "if total_remaining_surveyed <= 0:\n",
    "    print(\"All the people are surveyed, if you want to increase survey count, increase the count in traits_and_counts variable at top\")\n",
    "    sys.exit()\n",
    "    \n",
    "    \n",
    "for traits, counts in traits_dict.items():\n",
    "    if counts <= 0:\n",
    "        continue\n",
    "    while True:\n",
    "        input_message = f\"Generate survey answers from {counts} people.\\nAll of the surveyed people are {audience}\\n\"\n",
    "        input_message += f'The title of the survey: {title}\\n'\n",
    "        input_message += f'{counts} of the surveyed people have this trait: {traits}\\n'\n",
    "        input_message += f'Extremely Important Note: You must compulsory give answers to all the questions provided below. Do not skip any questions.\\n'\n",
    "        print(input_message)\n",
    "        for ind, question in enumerate(questions, 1):\n",
    "            input_message += f'Question{ind}: {questions[ind-1]}\\n'\n",
    "        total_surveyed = sum([c for _, c in traits_dict.items()])\n",
    "        try:\n",
    "            res = chain.invoke({\"input\": input_message})\n",
    "        except Exception as e:\n",
    "            print('OpenAI Error', e)\n",
    "            print()\n",
    "            print()\n",
    "            continue\n",
    "        write_txt(txt_file, str(res))\n",
    "        responses = output_parser(res)\n",
    "        if responses is None:\n",
    "            continue\n",
    "        final_responses = []\n",
    "        for data in responses:\n",
    "            continue_for = False\n",
    "            if type(data) == dict:\n",
    "                for ind, question in enumerate(questions):\n",
    "                    try:\n",
    "                        data[f'answer{ind+1}']\n",
    "                    except:\n",
    "                        write_txt(txt_file, f\"\\nanswer{ind+1}-not-found---------------------------------------\\n\")\n",
    "                        continue_for = True\n",
    "                        break\n",
    "                if continue_for:\n",
    "                    continue\n",
    "                final_responses.append(data)\n",
    "        for data in final_responses:\n",
    "            person_number += 1\n",
    "            lst = [traits, person_number]\n",
    "            for ind, question in enumerate(questions):\n",
    "                lst.append(data[f'answer{ind+1}'])\n",
    "            write_csv(output_file, lst)\n",
    "        write_txt(txt_file, \"\\nCompleted---------------------------------------\\n\\n\\n\")\n",
    "        total_processed_row += len(final_responses)\n",
    "        counts = counts - len(final_responses)\n",
    "        print('Remaining traits:', traits_dict)\n",
    "        print(\"Total responses given by model:\", len(final_responses))\n",
    "        print(\"Total processed responses:\", total_processed_row)\n",
    "        print(final_responses)\n",
    "        print()\n",
    "        print()\n",
    "        if counts <= 0:\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e21303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a5521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
